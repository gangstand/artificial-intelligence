import telebot
from telebot import types
import cv2
import numpy as np
import os.path
import glob
import shutil
import os


file_path = "img/image.jpeg"
token = '2059633155:AAEFOPWn_wA-TpmxCTcXr-hoYsHCoQhNUX8'
bot = telebot.TeleBot(token)


@bot.message_handler(commands=["start"])
def start(m):
    keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True)
    keyboard.add(*[types.KeyboardButton(name) for name in
                   ['Ð¡Ð¾Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚ÑŒ Ð¼Ð°Ð³Ð¸ÑŽðŸ”¥', 'Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµâ„¹', 'Ð“ÐµÐ½Ð¸Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°ðŸ§ ']])
    bot.send_message(m.chat.id, '---ðŸŽ‰Artificial Intelligence Telegram BotðŸŽ‰---\nÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð² Ð½Ð° Ñ„Ð¾Ñ‚Ð¾ Ð¸ Ð²Ð¸Ð´ÐµÐ¾. \nÐ’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ:', reply_markup=keyboard)


@bot.message_handler(content_types=['text'])
def message(message):
    if message.text == 'Ð¡Ð¾Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚ÑŒ Ð¼Ð°Ð³Ð¸ÑŽðŸ”¥':
        keyboardgostart = types.ReplyKeyboardMarkup(resize_keyboard=True)
        keyboardgostart.add(*[types.KeyboardButton(name) for name in ['Ð’Ð¸Ð´ÐµÐ¾ðŸ“¼', 'Ð¤Ð¾Ñ‚Ð¾ðŸ–¼']])
        bot.send_message(message.chat.id, 'Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð’Ð¸Ð´ÐµÐ¾ Ð¸Ð»Ð¸ Ð¤Ð¾Ñ‚Ð¾', reply_markup=keyboardgostart)
    elif message.text == 'Ð“ÐµÐ½Ð¸Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°ðŸ§ ':
        bot.send_message(message.chat.id, 'Ð“ÐµÐ½Ð¸Ð¸ Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ñ‹ 1 ÐºÑƒÑ€ÑÐ° ÐºÐ¾Ð»Ð»ÐµÐ´Ð¶Ð°"Ð ÐšÐ¡Ð˜":\nÐ¡Ð±Ð¾ÐµÐ² ÐÑ€Ñ‚Ñ‘Ð¼: \nVk: vk.com/artem1ka  \nTg: @artemka2604 \nÐÐ¸ÐºÐ¸Ñ‚Ð° ÐšÑƒÐ»ÑŒÐ¿Ð¸Ð½Ð¾Ð²: \nVk: vk.com/drugyourgirl \nTg: @ag1ng ')
    elif message.text == 'Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµâ„¹':
        bot.send_message(message.chat.id, "Ð¢ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼Ð¼ Ð±Ð¾Ñ‚ Ð½Ð° Python'e. Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð² ÑÐµÐ±Ðµ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸: \nOpenCV \nPyTelegramBotApi")
    # ÐšÐ¾Ð´ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ Ð²Ð¸Ð´ÐµÐ¾
    elif message.text == 'Ð’Ð¸Ð´ÐµÐ¾ðŸ“¼':
        keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True)
        keyboard.add(*[types.KeyboardButton(name) for name in ['ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð’Ð¸Ð´ÐµÐ¾ðŸ“¼']])
        bot.send_message(message.chat.id, 'ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¼Ð½Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ð¸ Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Ð½Ð° ÐºÐ½Ð¾Ð¿ÐºÑƒðŸ“¼', reply_markup=keyboard)
        if os.path.isfile("video/video.mp4"):
            os.remove("video/video.mp4")
            print("success")
        else:
            print("File doesn't exists!")

        @bot.message_handler(content_types=['video'])
        def video(message):

            bot.send_message(message.chat.id, 'Ð’Ð¸Ð´ÐµÐ¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ðŸ“¼')
            file_info = bot.get_file(message.video.file_id)
            downloaded_file = bot.download_file(file_info.file_path)
            src = file_info.file_path
            with open("video/video.mp4", 'wb') as new_file:
                new_file.write(downloaded_file)

    elif message.text == 'ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð’Ð¸Ð´ÐµÐ¾ðŸ“¼':

        net = cv2.dnn.readNet('artificial_intelligence_files/yolov3.weights',
                              'artificial_intelligence_files/yolov3.cfg')
        classes = []
        with open('artificial_intelligence_files/coco.names', 'r') as f:
            classes = f.read().splitlines()
        cap = cv2.VideoCapture('video/video.mp4')

        try:
            file = open('video/video.mp4')
        except IOError as e:
            keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True)
            bot.send_message(message.chat.id, 'ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¼Ð½Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ð¸ Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Ð½Ð° ÐºÐ½Ð¾Ð¿ÐºÑƒðŸ“¼', reply_markup=keyboard)
        else:
            with file:

                a = 1000000

                length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

                length_frime_time = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) / 20
                print('Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ: ' + str(round(length_frime_time)) + ' Ð¼Ð¸Ð½ÑƒÑ‚.')

                bot.send_message(message.chat.id, 'Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ: ' + str(round(length_frime_time)) + ' Ð¼Ð¸Ð½.')

                while True:
                    length -= 1
                    _, img = cap.read()
                    height, width, _ = img.shape

                    blob = cv2.dnn.blobFromImage(img, 1 / 255, (416, 416), (0, 0, 0), swapRB=True, crop=False)
                    net.setInput(blob)
                    output_layers_names = net.getUnconnectedOutLayersNames()
                    layerOutputs = net.forward(output_layers_names)

                    boxes = []
                    confidences = []
                    class_ids = []

                    for output in layerOutputs:
                        for detection in output:
                            scores = detection[5:]
                            class_id = np.argmax(scores)
                            confidence = scores[class_id]
                            if confidence > 0.5:
                                center_x = int(detection[0] * width)
                                center_y = int(detection[1] * height)
                                w = int(detection[2] * width)
                                h = int(detection[3] * height)

                                x = int(center_x - w / 2)
                                y = int(center_y - h / 2)

                                boxes.append([x, y, w, h])
                                confidences.append((float(confidence)))
                                class_ids.append(class_id)

                    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

                    font = cv2.FONT_HERSHEY_PLAIN
                    colors = np.random.uniform(0, 255, size=(len(boxes), 3))
                    if len(indexes) > 0:
                        for i in indexes.flatten():
                            x, y, w, h = boxes[i]
                            label = str(classes[class_ids[i]])
                            confidence = str(round(confidences[i], 2))
                            color = colors[i]
                            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)
                            cv2.putText(img, label + " " + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)

                    cv2.imwrite('video/video_cadr/' + str(a) + '.jpg', img)
                    a += 1
                    if length < 1:
                        break
                img_array = []
                for filename in glob.glob('video/video_cadr/*.jpg'):
                    img = cv2.imread(filename)
                    height, width, layers = img.shape
                    size = (width, height)
                    img_array.append(img)

                out = cv2.VideoWriter('project.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 27, size)

                for i in range(len(img_array)):
                    out.write(img_array[i])


                shutil.rmtree("video\\video_cadr", ignore_errors=True)
                path = "video\\video_cadr"
                os.mkdir(path)
                keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True)
                keyboard.add(*[types.KeyboardButton(name) for name in ['ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð’Ð¸Ð´ÐµÐ¾']])
                bot.send_message(message.chat.id, 'Ð’Ð¸Ð´ÐµÐ¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾', reply_markup=keyboard)

    elif message.text == 'ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð’Ð¸Ð´ÐµÐ¾':
        bot.send_video(message.chat.id, open("project.mp4", 'rb'))


    # Ð¤Ð¾Ñ‚Ð¾ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ
    elif message.text == 'Ð¤Ð¾Ñ‚Ð¾ðŸ–¼':
        keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True)
        keyboard.add(*[types.KeyboardButton(name) for name in ['ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð¤Ð¾Ñ‚Ð¾ðŸ–¼']])
        bot.send_message(message.chat.id, 'ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¼Ð½Ðµ Ñ„Ð¾Ñ‚Ð¾ Ð¸ Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Ð½Ð° ÐºÐ½Ð¾Ð¿ÐºÑƒðŸ–¼', reply_markup=keyboard)
        if os.path.isfile("img/image.jpeg"):
            os.remove("img/image.jpeg")
            print("success")
        else:
            print("File doesn't exists!")

        @bot.message_handler(content_types=['photo'])
        def handle(message):
            bot.send_message(message.chat.id, 'Ð¤Ð¾Ñ‚Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ðŸ–¼')
            fileID = message.photo[-1].file_id
            file = bot.get_file(fileID)
            down_file = bot.download_file(file.file_path)
            with open("img/image.jpeg", "wb") as f:
                f.write(down_file)

    elif message.text == 'ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð¤Ð¾Ñ‚Ð¾ðŸ–¼':
            try:
                file = open('img/image.jpeg')
            except IOError as e:
                keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True)
                bot.send_message(message.chat.id, 'ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¼Ð½Ðµ Ñ„Ð¾Ñ‚Ð¾ Ð¸ Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Ð½Ð° ÐºÐ½Ð¾Ð¿ÐºÑƒðŸ–¼', reply_markup=keyboard)
            else:
                with file:

                    net = cv2.dnn.readNet('artificial_intelligence_files/yolov3.weights',
                                          'artificial_intelligence_files/yolov3.cfg')
                    classes = []
                    with open('artificial_intelligence_files/coco.names', 'r') as f:
                        classes = f.read().splitlines()

                        img = cv2.imread('img/image.jpeg')
                        height, width, _ = img.shape

                        blob = cv2.dnn.blobFromImage(img, 1 / 255, (416, 416), (0, 0, 0), swapRB=True, crop=False)
                        net.setInput(blob)
                        output_layers_names = net.getUnconnectedOutLayersNames()
                        layerOutputs = net.forward(output_layers_names)

                        boxes = []
                        confidences = []
                        class_ids = []

                        for output in layerOutputs:
                            for detection in output:
                                scores = detection[5:]
                                class_id = np.argmax(scores)
                                confidence = scores[class_id]
                                if confidence > 0.5:
                                    center_x = int(detection[0] * width)
                                    center_y = int(detection[1] * height)
                                    w = int(detection[2] * width)
                                    h = int(detection[3] * height)

                                    x = int(center_x - w / 2)
                                    y = int(center_y - h / 2)

                                    boxes.append([x, y, w, h])
                                    confidences.append((float(confidence)))
                                    class_ids.append(class_id)

                        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

                        font = cv2.FONT_HERSHEY_PLAIN
                        colors = np.random.uniform(0, 255, size=(len(boxes), 3))

                        for i in indexes.flatten():
                            x, y, w, h = boxes[i]
                            label = str(classes[class_ids[i]])
                            confidence = str(round(confidences[i], 2))
                            color = colors[i]
                            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)
                            cv2.putText(img, label + " " + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)

                        cv2.imwrite("img/img_finished.jpeg", img)
                bot.send_photo(message.chat.id, open("img/img_finished.jpeg", 'rb'))

bot.polling(none_stop=True)
